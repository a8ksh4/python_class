{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D - Pandas\n",
    "\n",
    "**Topics:** Pandas basics, includeng row and column selections, index, column names, data types and type-casting, and a bit more. \n",
    "\n",
    "The name \"Pandas\" comes from \"Panel Data\" and \"Python Data Analysis\". \"Panel Data\" refers to two dimensoinal data, often including measurements over time - time series - or collections of things/events. The term \"Pandas\" is a blend of these concepts, reflecting the library's purpose of providing data structures and data analysis tools in Python.\n",
    "\n",
    "**Pandas** are playfull and memorable, just like **Pandas**!\n",
    "\n",
    "Pandas has two types of objects, **DataFrames** and **Series**.  A dataframe has rows and columns, like a spreadsheet - two dimensional.  A single row or column from a dataframe is a Series.  If we select a single column from a DataFrame, we get a series, a single dimensional object, and a series can be inserted into a df column. \n",
    "\n",
    "By convention, we'll import pandas as \"pd\" to save us some typing.\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    " It's also common to call a single dataframe that we're working on \"df\", but it's a good idea to use a longer more descriptive name for complex tasks.\n",
    "\n",
    "    df = pd.read_csv('my_data.csv')\n",
    "\n",
    "There is functionality built into pd, as well as the dataframe and series objects that we create that we will use to manipulate the dataframe and series.  For example, we use these DataFrame functions a lot to view our data:\n",
    "\n",
    "    df.info()  # show a summary of columns and data types in the dataframe. \n",
    "    df.head()  # show the top few rows of the dataframe.\n",
    "    df.tail()  # few bottom rows\n",
    "    df.describe()\n",
    "    ...and more\n",
    "\n",
    "And there are functions we call from pd to manipulate the dataframes:\n",
    "\n",
    "    big_df = pd.concat(a_list_of_small_dataframes)  # concatenate dataframes together\n",
    "    ...and more\n",
    "\n",
    "## Creating a Dataframe\n",
    "We can create an empty dataframe:\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "But generally (or always) we'll want to load some data to make a dataframe. Common ways to do this follow. Reference the documentation to see optional arguments to use, like \"skip_rows\" to skip padding rows at the top of an excel or csv file, or use_cols to only import specific columns. \n",
    "\n",
    "**Excel Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n",
    "\n",
    "    df = pd.read_excel(file_name, ... engine ...)\n",
    "\n",
    "**CSV Files or dat Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "You may need to set the delimeter for some csv files. \n",
    "\n",
    "    df = pd.read_csv(file_name, ...)\n",
    "    df = pd.read_table(file_name, ...)\n",
    "\n",
    "**json Data** - https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "Useful for data loaded from the web.  This is what we use in the D1-Pandas_Example notebook.\n",
    "\n",
    "    df = pd.read_json(json_data, ...)\n",
    "\n",
    "**Dictionary of Lists to DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list of dictionaries to DataFrame**\n",
    "Same idea as above, but slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'},\n",
    "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "\n",
    "In the following code cell, use these functions to look at information about the dataframe:\n",
    "\n",
    "    .info(), .describe(), and .head() \n",
    "\n",
    "And print thef following properties of the dataframe, like: `df.shape`\n",
    "\n",
    "    .columns, .size, .shape\n",
    "\n",
    "* What data type is each of the columns?\n",
    "* How many rows and columns are there?\n",
    "* What's the relationship between shape and size?\n",
    "* Use a list comprehension to overwrite df.columns and make the comlumn names upper case.  `df.columns = [... ... df.comumns]`\n",
    "\n",
    "Scroll through the DataFrame documentation to get an idea of what methods are built into it: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *We'll use this \"df\" for a few exercises below, so make sure to run this cell before continuing.*\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/iris.csv\")\n",
    "# You can also try saving iris.csv in the directory with your notebook and opening it from a local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_length_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>2.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.929135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.850395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.811025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.968505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species  \\\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa   \n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa   \n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa   \n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa   \n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa   \n",
       "\n",
       "   sepal_length_inches  \n",
       "0             2.007875  \n",
       "1             1.929135  \n",
       "2             1.850395  \n",
       "3             1.811025  \n",
       "4             1.968505  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here.  You can re-run the above cell if you mess up your dataframe.\n",
    "# print(df....)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Columns by name:\n",
    "We can select a single column by passing it's name in brackets, like: `df['column_name']`\n",
    "\n",
    "And we can select multiple columns by passing a list of column names in nested brackets: `df[['column1', 'column2', ...]]`\n",
    "\n",
    "This is a bit like string or list slicing, but using names or lists of names to take a selection of the available columns.\n",
    "\n",
    "We can use this to both get values from columns or to assign values directly into one or more columns, or to create new columns of some name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single column is a series object, so sepal_lenghts is a series.\n",
    "sls = df['sepal_length']\n",
    "print('Some of the sepal lenghths are:\\n', sls)\n",
    "print('All the lenghts are:\\n', list(sls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Just like we did for the dataframe above, let's explore this \"sls\" series object.\n",
    "\n",
    "* Use the `.info(), .shape, .size` properties to learn about the object. \n",
    "* And Let's try some more interesting functions built into series objects: `.sum(), .value_counts(), .mean()`\n",
    "* Check if the series is greater than 3.  What is returned?  This list of True/False values is important for a future concept, \"masks\", for selecting rows.\n",
    "* Scroll through some of the methods listed in the series documentation here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and manipulating columns of data:\n",
    "We can perform mathematical operations on columns of data and put the result into a new or overwrite an existing column.  For example, if we want to add a column with units inches instead of cm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepal_length_inches'] = df['sepal_length'] * 0.393701\n",
    "\n",
    "length_columns = sorted([c for c in df.columns if 'length' in c])\n",
    "print('length comparison:\\n', df[length_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you perform operations on a column, like multiplying the 'sepal_length' column by 0.393, that operation is broadcast across all rows in the column.  \n",
    "\n",
    "And when we perform operation aginst two columns, each row in the columns is matched with the same index row in the other column for the operation, as with the width_differenc calculation below.\n",
    "\n",
    "We can also select multiple columns py passing the columns in [], like: `df[['petal_length', 'petal_width']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['width_difference'] = (df['sepal_width'] - df['petal_width']).abs()\n",
    "\n",
    "# Alternate ways of selecting and printing columns are commented out below:\n",
    "\n",
    "# width_columns = df.columns[df.columns.str.contains('width')]\n",
    "# width_columns = ['sepal_width', 'petal_width', 'width_difference']\n",
    "width_columns = sorted([c for c in df.columns if 'width' in c])\n",
    "\n",
    "print('Widths:')\n",
    "# print(df[['sepal_width', 'petal_width', 'width_difference']])\n",
    "print(df[width_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Rows with loc and iloc\n",
    "**.loc** vs **.iloc**\n",
    "* .loc selects rows with particular labels in the series or dataframe index\n",
    "  * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "* .iloc selects rows at integer locations within the series or dataframe.\n",
    "  * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age          SSN          City\n",
      "0    Alice   25  123-45-6789      New York\n",
      "1      Bob   30  234-56-7890   Los Angeles\n",
      "2  Charlie   35  345-67-8901       Chicago\n",
      "3    David   40  456-78-9012       Houston\n",
      "4      Eve   45  567-89-0123       Phoenix\n",
      "5    Frank   50  678-90-1234  Philadelphia\n",
      "6    Grace   55  789-01-2345   San Antonio\n",
      "7   Hannah   60  890-12-3456     San Diego\n",
      "8    Isaac   65  901-23-4567        Dallas\n",
      "9     Jack   70  123-45-5789      San Jose\n"
     ]
    }
   ],
   "source": [
    "# generate dataframe with ten people wih random ages, social security numbers, ages, cities, and sex:\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', \n",
    "             'Grace', 'Hannah', 'Isaac', 'Jack'],\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'SSN': ['123-45-6789', '234-56-7890', '345-67-8901', '456-78-9012', \n",
    "            '567-89-0123', '678-90-1234', '789-01-2345', '890-12-3456', \n",
    "            '901-23-4567', '123-45-5789'],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', \n",
    "             'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose'],\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/titaninc.csv\")\n",
    "# Note that by default, an arbitrary numerical index is assigned to the rows.\n",
    "# That default index would match exactly with the numeric address of each row, \n",
    "# so it is not useful for this example. \n",
    "# We instead set the passenger ID as the index - loc refers to this, and iloc \n",
    "# refers to the literal numerical address of each row. \n",
    "df = df.set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>PassId</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked PassId  \n",
       "PassengerId                                                                 \n",
       "1                1      0         A/5 21171   7.2500   NaN        S      1  \n",
       "2                1      0          PC 17599  71.2833   C85        C      2  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S      3  \n",
       "4                1      0            113803  53.1000  C123        S      4  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So lets print row number 2 using iloc, and the passenger with PassengerId 2 using loc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loc:\n",
      " Cumings, Mrs. John Bradley (Florence Briggs Thayer)\n",
      "iloc:\n",
      " Heikkinen, Miss. Laina\n"
     ]
    }
   ],
   "source": [
    "print('loc:\\n', df.loc[2]['Name'])\n",
    "print('iloc:\\n', df.iloc[2]['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc selectoin of rows and columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iloc selection of rows and columns\n",
    "iloc can multiple rows and columns by their address and slices of rows and columns:\n",
    "\n",
    "* **Multiple rows**: `df.iloc[[2,3,4]]\n",
    "* **Multiple rows and cols**: `df.iloc[[2,3], [0,1,2]]\n",
    "* **Slice of rows**:\n",
    "  * `df.iloc[2:5]`\n",
    "  * `df.iloc[:5]`\n",
    "* **slice of rows and cols**: `df.iloc[1:3, 1:4]`\n",
    "\n",
    "A simple example of use of this might be if I wanted to split my data into a training set and a testing set for some machine learning prediction algorithm.  I would randomize order of the data, then select 70% of the rows for training and 30% for testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ramdomize order of the rows\n",
    "df_randomized = df.sample(frac=1)\n",
    "\n",
    "# figure ou thow many rows we need:\n",
    "training_size = int(len(df_randomized) * 0.7)\n",
    "testing_size = len(df_randomized) - training_size\n",
    "\n",
    "# split the data\n",
    "df_trianing = df_randomized.iloc[:training_size]\n",
    "df_testing = df_randomized.iloc[training_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Use iloc to show these views of the titanic passengers:\n",
    "* The 4th through 6th passengers\n",
    "* Even numbered passenger rows (not even PassengerId) and columns 1:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Over rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Type Conversions\n",
    "**String to Numeric**\n",
    "**String to Datetime**\n",
    "**Datetime to Numeric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .apply for arbitrary operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Note Regading inplace=True\n",
    "changed_dataframe = df.some_modification()\n",
    "\n",
    "Pandas is phasing out inplace modification.  It can still be done by passing the 'inplace=True'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Concatenation\n",
    "When we read in multiple files, we can concatenate them into a single dataframe.  \n",
    "Example should show adding an identifier row and pulling date from file name.\n",
    "\n",
    "## Join Operations\n",
    "\n",
    "## Stack and Unstack (sort of like a povit table)\n",
    "**Stack** - This function pivots the columns of a DataFrame into its index, effectively \"stacking\" the data vertically. It converts a DataFrame from a wide format to a long format.\n",
    "**Unstack** - This is the reverse of stack. It pivots the index of a DataFrame back into columns, converting it from a long format to a wide format.\n",
    "\n",
    "What does this mean and why!!!???\n",
    "\n",
    "## Plotting\n",
    "\n",
    "## Exporting files\n",
    "### Plain Excel\n",
    "### Multiple Sheets Excel\n",
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dataframe\n",
    "Just skim over this for the general idea on how it works, and come back to each method for importing data as you need it. \n",
    "\n",
    "## Empty Dataframe\n",
    "Why would we want an empty dataframe?  I think it's generally not needed... but maybe there's a good case for starting with an empty df... \n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "## From a CSV file\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "## From an Excel file\n",
    "The sheet name is only needed if we have multiple sheets in the .xlsx.\n",
    "\n",
    "    df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "## From a list of lists or tuples\n",
    "We need to specify the column names in this case:\n",
    "\n",
    "    data = [[1, 2], [3, 4], [5, 6]]\n",
    "    df = pd.DataFrame(data, columns=['A', 'B'])\n",
    "\n",
    "## From a dictionary \n",
    "The dictionary keys are the **column** names, and the each list is a column of data. \n",
    "\n",
    "    data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "## From a database\n",
    "Note that a database connection, called \"conn\" here, is a pretty standard thing.  You can create a connection to many database types and pass the connectin and query to pd.read_sql_query and it will just work.  Sqlite3 is a file based database that doesn't require a server to host it. \n",
    "\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    df = pd.read_sql_query('SELECT * FROM table_name', conn)\n",
    "\n",
    "## From an html table\n",
    "Note that you can also generate html tables from dataframes... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
