{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D - Pandas\n",
    "\n",
    "**Topics:** Pandas basics, includeng row and column selections, index, column names, data types and type-casting, and a bit more. \n",
    "\n",
    "The name \"Pandas\" comes from \"Panel Data\" and \"Python Data Analysis\". \"Panel Data\" refers to a particular type of data that is multidimensional, involving measurements over time. The term \"Pandas\" is a blend of these concepts, reflecting the library's purpose of providing data structures and data analysis tools in Python.\n",
    "\n",
    "**Pandas** are playfull and memorable, just like **Pandas**!\n",
    "\n",
    "Pandas has two types of objects, DataFrames and Series.  A dataframe has rows and columns, like a spreadsheet - two dimensional.  A single row or column from a dataframe is a Series.  If we select a single column from a DataFrame, we get a series, a single dimensional object, and a series can be inserted into a df column. \n",
    "\n",
    "By convention, we'll import pandas as \"pd\" to save us some typing.\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    " It's also common to call a single dataframe we're working on \"df\", but it's a good idea to use a longer more descriptive name for complex tasks.\n",
    "\n",
    "There is functionality built into pd, as well as the dataframe and series objects that we create that we will use to manipulate the dataframe and series.  For example, we use these DataFrame functions a lot to view our data:\n",
    "\n",
    "    df.info()  # show a summary of columns and data types in the dataframe. \n",
    "    df.head()  # show the top few rows of the dataframe.\n",
    "    df.tail()  # few bottom rows\n",
    "    ...and more\n",
    "\n",
    "And there are functions we call from pd to manipulate the dataframes:\n",
    "\n",
    "    new_df = pd.concat(a_list_of_dataframes)  # concatenate dataframes together\n",
    "    ...and more\n",
    "\n",
    "## Creating a Dataframe\n",
    "We can create an empty dataframe:\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "But generally (or always) we'll want to load some data to make a dataframe. Common ways to do this follow. Reference the documentation to see optional arguments to use, like \"skip_rows\" to skip padding rows at the top of an excel or csv file, or use_cols to only import specific columns. \n",
    "\n",
    "**Excel Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n",
    "\n",
    "    df = pd.read_excel(file_name, ... engine ...)\n",
    "\n",
    "**CSV Files or dat Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "You may need to set the delimeter for some csv files. \n",
    "\n",
    "    df = pd.read_csv(file_name, ...)\n",
    "    df = pd.read_table(file_name, ...)\n",
    "\n",
    "**json Data** - https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "Useful for data loaded from the web.  This is what we use in the D1-Pandas_Example notebook.\n",
    "\n",
    "    df = pd.read_json(json_data, ...)\n",
    "\n",
    "**Dictionary of Lists to DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list of dictionaries to DataFrame**\n",
    "Same idea as above, but slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'},\n",
    "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "\n",
    "In the following code cell, use .info(), .describe(), and .head() to see what kind of data has been loaded into the dataframe.  \n",
    "\n",
    "*We'll use this \"df\" for a few exercises below, so make sure to run this cell before continuing.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Columns:\n",
    "We can both asign or select single column from a datafram with df['column_name'].  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sepal lenghts are:\n",
      " 0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: sepal_length, Length: 150, dtype: float64\n",
      "and in inches:\n",
      " 0      2.007875\n",
      "1      1.929135\n",
      "2      1.850395\n",
      "3      1.811025\n",
      "4      1.968505\n",
      "         ...   \n",
      "145    2.637797\n",
      "146    2.480316\n",
      "147    2.559057\n",
      "148    2.440946\n",
      "149    2.322836\n",
      "Name: sepal_length_inches, Length: 150, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# a single column is a series, so sepal_lenghts is a series.\n",
    "sepal_lenghths = df['sepal_length']\n",
    "print('the sepal lenghts are:\\n', sepal_lenghths)\n",
    "\n",
    "# we're creating a new column in the dataframe here.\n",
    "df['sepal_length_inches'] = df['sepal_length'] * 0.393701\n",
    "print('and in inches:\\n', df['sepal_length_inches'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good time to mention broadcasting - When you perform a mathematical operatino on a column, the operatoin is broadcast to every value in the column.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Selecting Rows:\n",
    "\n",
    "## Iterating Over rows\n",
    "\n",
    "## Type Conversions\n",
    "\n",
    "## Note Regading inplace=True\n",
    "changed_dataframe = df.some_modification()\n",
    "\n",
    "Pandas is phasing out inplace modification.  It can still be done by passing the 'inplace=True'\n",
    "\n",
    "## Type Conversions\n",
    "Freqently string to numeric\n",
    "String to datetime\n",
    "\n",
    "### Datetime Conversions\n",
    "\n",
    "## String Operations\n",
    "\n",
    "\n",
    "## Concatenation\n",
    "When we read in multiple files, we can concatenate them into a single dataframe.  \n",
    "Example should show adding an identifier row and pulling date from file name.\n",
    "\n",
    "## Join Operations\n",
    "\n",
    "## Stack and Unstack (sort of like a povit table)\n",
    "**Stack** - This function pivots the columns of a DataFrame into its index, effectively \"stacking\" the data vertically. It converts a DataFrame from a wide format to a long format.\n",
    "**Unstack** - This is the reverse of stack. It pivots the index of a DataFrame back into columns, converting it from a long format to a wide format.\n",
    "\n",
    "What does this mean and why!!!???\n",
    "\n",
    "## Plotting\n",
    "\n",
    "## Exporting files\n",
    "### Plain Excel\n",
    "### Multiple Sheets Excel\n",
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dataframe\n",
    "Just skim over this for the general idea on how it works, and come back to each method for importing data as you need it. \n",
    "\n",
    "## Empty Dataframe\n",
    "Why would we want an empty dataframe?  I think it's generally not needed... but maybe there's a good case for starting with an empty df... \n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "## From a CSV file\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "## From an Excel file\n",
    "The sheet name is only needed if we have multiple sheets in the .xlsx.\n",
    "\n",
    "    df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "## From a list of lists or tuples\n",
    "We need to specify the column names in this case:\n",
    "\n",
    "    data = [[1, 2], [3, 4], [5, 6]]\n",
    "    df = pd.DataFrame(data, columns=['A', 'B'])\n",
    "\n",
    "## From a dictionary \n",
    "The dictionary keys are the **column** names, and the each list is a column of data. \n",
    "\n",
    "    data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "## From a database\n",
    "Note that a database connection, called \"conn\" here, is a pretty standard thing.  You can create a connection to many database types and pass the connectin and query to pd.read_sql_query and it will just work.  Sqlite3 is a file based database that doesn't require a server to host it. \n",
    "\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    df = pd.read_sql_query('SELECT * FROM table_name', conn)\n",
    "\n",
    "## From an html table\n",
    "Note that you can also generate html tables from dataframes... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
