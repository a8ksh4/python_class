{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D - Pandas\n",
    "\n",
    "**Topics:** Pandas basics, includeng row and column selections, index, column names, data types and type-casting, and a bit more. \n",
    "\n",
    "The name \"Pandas\" comes from \"Panel Data\" and \"Python Data Analysis\". \"Panel Data\" refers to two dimensoinal data, often including measurements over time - time series - or collections of things/events. The term \"Pandas\" is a blend of these concepts, reflecting the library's purpose of providing data structures and data analysis tools in Python.\n",
    "\n",
    "**Pandas** are playfull and memorable, just like **Pandas**!\n",
    "\n",
    "Pandas has two types of objects, **DataFrames** and **Series**.  A dataframe has rows and columns, like a spreadsheet - two dimensional.  A single row or column from a dataframe is a Series.  If we select a single column from a DataFrame, we get a series, a single dimensional object, and a series can be inserted into a df column. \n",
    "\n",
    "By convention, we'll import pandas as \"pd\" to save us some typing.\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    " It's also common to call a single dataframe that we're working on \"df\", but it's a good idea to use a longer more descriptive name for complex tasks.\n",
    "\n",
    "    df = pd.read_csv('my_data.csv')\n",
    "\n",
    "There is functionality built into pd, as well as the dataframe and series objects that we create that we will use to manipulate the dataframe and series.  For example, we use these DataFrame functions a lot to view our data:\n",
    "\n",
    "    df.info()  # show a summary of columns and data types in the dataframe. \n",
    "    df.head()  # show the top few rows of the dataframe.\n",
    "    df.tail()  # few bottom rows\n",
    "    df.describe()\n",
    "    ...and more\n",
    "\n",
    "And there are functions we call from pd to manipulate the dataframes:\n",
    "\n",
    "    big_df = pd.concat(a_list_of_small_dataframes)  # concatenate dataframes together\n",
    "    ...and more\n",
    "\n",
    "## Creating a Dataframe\n",
    "We can create an empty dataframe:\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "But generally (or always) we'll want to load some data to make a dataframe. Common ways to do this follow. Reference the documentation to see optional arguments to use, like \"skip_rows\" to skip padding rows at the top of an excel or csv file, or use_cols to only import specific columns. \n",
    "\n",
    "**Excel Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n",
    "\n",
    "    df = pd.read_excel(file_name, ... engine ...)\n",
    "\n",
    "**CSV Files or dat Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "You may need to set the delimeter for some csv files. \n",
    "\n",
    "    df = pd.read_csv(file_name, ...)\n",
    "    df = pd.read_table(file_name, ...)\n",
    "\n",
    "**json Data** - https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "Useful for data loaded from the web.  This is what we use in the D1-Pandas_Example notebook.\n",
    "\n",
    "    df = pd.read_json(json_data, ...)\n",
    "\n",
    "**Dictionary of Lists to DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list of dictionaries to DataFrame**\n",
    "Same idea as above, but slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'},\n",
    "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "\n",
    "In the following code cell, use these functions to look at information about the dataframe:\n",
    "\n",
    "    .info(), .describe(), and .head() \n",
    "\n",
    "And print thef following properties of the dataframe, like: `df.shape`\n",
    "\n",
    "    .columns, .size, .shape\n",
    "\n",
    "* What data type is each of the columns?\n",
    "* How many rows and columns are there?\n",
    "* What's the relationship between shape and size?\n",
    "* Use a list comprehension to overwrite df.columns and make the comlumn names upper case.  `df.columns = [... ... df.comumns]`\n",
    "\n",
    "Scroll through the DataFrame documentation to get an idea of what methods are built into it: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *We'll use this \"df\" for a few exercises below, so make sure to run this cell before continuing.*\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here.  You can re-run the above cell if you mess up your dataframe.\n",
    "# print(df....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Columns by name:\n",
    "We can select a single column by passing it's name in brackets, like: `df['column_name']`\n",
    "\n",
    "And we can select multiple columns by passing a list of column names in nested brackets: `df[['column1', 'column2', ...]]`\n",
    "\n",
    "This is a bit like string or list slicing, but using names or lists of names to take a selection of the available columns.\n",
    "\n",
    "We can use this to both get values from columns or to assign values directly into one or more columns, or to create new columns of some name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single column is a series object, so sepal_lenghts is a series.\n",
    "sls = df['sepal_length']\n",
    "print('some of the sepal lenghths are:\\n', str(sls))\n",
    "print('all the sepal lenghts are:\\n', list(sls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Just like we did for the dataframe above, let's explore this \"sls\" series object.\n",
    "\n",
    "* Use the `.info(), .shape, .size` properties to learn about the object. \n",
    "* And Let's try some more interesting functions built into series objects: `.sum(), .value_counts(), .mean()`\n",
    "* Check if the series is greater than 3.  What is returned?  This list of True/False values is important for a future concept, \"masks\", for selecting rows.\n",
    "* Scroll through some of the methods listed in the series documentation here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and manipulating columns of data:\n",
    "We can perform mathematical operations on columns of data and put the result into a new or existing column.  For example, if we want to add a column with units inches instead of cm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepal_length_inches'] = df['sepal_length'] * 0.393701\n",
    "length_columns = sorted([c for c in df.columns if 'length' in c])\n",
    "print('length comparison:\\n', df[length_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you perform operations on a column, like multiplying the 'sepal_length' column by 0.393, that operation is broadcast across all rows in the column.  \n",
    "\n",
    "We can also select multiple columns py passing the columns in [], like: `df[['petal_length', 'petal_width']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['width_difference'] = (df['sepal_width'] - df['petal_width']).abs()\n",
    "\n",
    "\n",
    "print('Widths:')\n",
    "print(df[['sepal_width', 'petal_width', 'width_difference']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Rows with loc and iloc\n",
    "**.loc** vs **.iloc**\n",
    "* .loc selects rows with particular labels in the series or dataframe index\n",
    "* .iloc selects rows at integer locations within the series or dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating Over rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.iterrows():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Type Conversions\n",
    "**String to Numeric**\n",
    "**String to Datetime**\n",
    "**Datetime to Numeric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .apply for arbitrary operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Note Regading inplace=True\n",
    "changed_dataframe = df.some_modification()\n",
    "\n",
    "Pandas is phasing out inplace modification.  It can still be done by passing the 'inplace=True'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Concatenation\n",
    "When we read in multiple files, we can concatenate them into a single dataframe.  \n",
    "Example should show adding an identifier row and pulling date from file name.\n",
    "\n",
    "## Join Operations\n",
    "\n",
    "## Stack and Unstack (sort of like a povit table)\n",
    "**Stack** - This function pivots the columns of a DataFrame into its index, effectively \"stacking\" the data vertically. It converts a DataFrame from a wide format to a long format.\n",
    "**Unstack** - This is the reverse of stack. It pivots the index of a DataFrame back into columns, converting it from a long format to a wide format.\n",
    "\n",
    "What does this mean and why!!!???\n",
    "\n",
    "## Plotting\n",
    "\n",
    "## Exporting files\n",
    "### Plain Excel\n",
    "### Multiple Sheets Excel\n",
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dataframe\n",
    "Just skim over this for the general idea on how it works, and come back to each method for importing data as you need it. \n",
    "\n",
    "## Empty Dataframe\n",
    "Why would we want an empty dataframe?  I think it's generally not needed... but maybe there's a good case for starting with an empty df... \n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "## From a CSV file\n",
    "\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "## From an Excel file\n",
    "The sheet name is only needed if we have multiple sheets in the .xlsx.\n",
    "\n",
    "    df = pd.read_excel('data.xlsx', sheet_name='Sheet1')\n",
    "\n",
    "## From a list of lists or tuples\n",
    "We need to specify the column names in this case:\n",
    "\n",
    "    data = [[1, 2], [3, 4], [5, 6]]\n",
    "    df = pd.DataFrame(data, columns=['A', 'B'])\n",
    "\n",
    "## From a dictionary \n",
    "The dictionary keys are the **column** names, and the each list is a column of data. \n",
    "\n",
    "    data = {'A': [1, 2, 3], 'B': [4, 5, 6]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "## From a database\n",
    "Note that a database connection, called \"conn\" here, is a pretty standard thing.  You can create a connection to many database types and pass the connectin and query to pd.read_sql_query and it will just work.  Sqlite3 is a file based database that doesn't require a server to host it. \n",
    "\n",
    "    import sqlite3\n",
    "\n",
    "    conn = sqlite3.connect('database.db')\n",
    "    df = pd.read_sql_query('SELECT * FROM table_name', conn)\n",
    "\n",
    "## From an html table\n",
    "Note that you can also generate html tables from dataframes... \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
