{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D1 - Pandas Data Import and Selection\n",
    "**Index**\n",
    "* Creating a Dataframe\n",
    "* Selecting Columns by Name\n",
    "* Selecting Rows and Columns with loc and iloc\n",
    "* Selecting Rows with a mask\n",
    "* Selecting Rows with .where\n",
    "* Using .iterrows\n",
    "\n",
    "Pandas has two types of objects, **DataFrames** and **Series**.  A dataframe has rows and columns, like a spreadsheet - two dimensional.  A single row or column from a dataframe is a Series.  If we select a single column from a DataFrame, we get a series, a single dimensional object, and a series can be inserted into a df column. \n",
    "\n",
    "By convention, we'll import pandas as \"pd\" to save us some typing.\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    " It's also common to call a single dataframe that we're working on \"df\", but it's a good idea to use a longer more descriptive name for complex tasks.\n",
    "\n",
    "    df = pd.read_csv('my_data.csv')\n",
    "\n",
    "There is functionality built into pd, as well as the dataframe and series objects that we create that we will use to manipulate the dataframe and series.  For example, we use these DataFrame functions a lot to view our data:\n",
    "\n",
    "    df.info()  # show a summary of columns and data types in the dataframe. \n",
    "    df.head()  # show the top few rows of the dataframe.\n",
    "    df.tail()  # few bottom rows\n",
    "    df.describe()\n",
    "    ...and more\n",
    "\n",
    "And there are functions we call from pd to manipulate the dataframes:\n",
    "\n",
    "    big_df = pd.concat(a_list_of_small_dataframes)  # concatenate dataframes together\n",
    "    ...and more\n",
    "\n",
    "## Creating a Dataframe\n",
    "We can create an empty dataframe:\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "But generally (or always) we'll want to load some data to make a dataframe. Common ways to do this follow. Reference the documentation to see optional arguments to use, like \"skip_rows\" to skip padding rows at the top of an excel or csv file, or use_cols to only import specific columns. \n",
    "\n",
    "**Excel Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html\n",
    "\n",
    "    df = pd.read_excel(file_name, ... engine ...)\n",
    "\n",
    "**CSV Files or dat Files** - https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html\n",
    "You may need to set the delimeter for some csv files. \n",
    "\n",
    "    df = pd.read_csv(file_name, ...)\n",
    "    df = pd.read_table(file_name, ...)\n",
    "\n",
    "**json Data** - https://pandas.pydata.org/docs/reference/api/pandas.read_json.html\n",
    "Useful for data loaded from the web.  This is what we use in the D1-Pandas_Example notebook.\n",
    "\n",
    "    df = pd.read_json(json_data, ...)\n",
    "\n",
    "**Dictionary of Lists to DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**list of dictionaries to DataFrame**\n",
    "Same idea as above, but slightly different format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   25     New York\n",
      "1      Bob   30  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "    {'Name': 'Alice', 'Age': 25, 'City': 'New York'},\n",
    "    {'Name': 'Bob', 'Age': 30, 'City': 'Los Angeles'},\n",
    "    {'Name': 'Charlie', 'Age': 35, 'City': 'Chicago'}\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "\n",
    "In the following code cell, use these functions to look at information about the dataframe:\n",
    "\n",
    "    .info(), .describe(), and .head() \n",
    "\n",
    "And print thef following properties of the dataframe, like: `df.shape`\n",
    "\n",
    "    .columns, .size, .shape\n",
    "\n",
    "* What data type is each of the columns?\n",
    "* How many rows and columns are there?\n",
    "* What's the relationship between shape and size?\n",
    "* Use a list comprehension to overwrite df.columns and make the comlumn names upper case.  `df.columns = [... ... df.comumns]`\n",
    "\n",
    "Scroll through the DataFrame documentation to get an idea of what methods are built into it: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *We'll use this \"df\" for a few exercises below, so make sure to run this cell before continuing.*\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/iris.csv\")\n",
    "# You can also try saving iris.csv in the directory with your notebook and opening it from a local path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>sepal_length_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>2.007875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.929135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.850395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.811025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>1.968505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species  \\\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa   \n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa   \n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa   \n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa   \n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa   \n",
       "\n",
       "   sepal_length_inches  \n",
       "0             2.007875  \n",
       "1             1.929135  \n",
       "2             1.850395  \n",
       "3             1.811025  \n",
       "4             1.968505  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here.  You can re-run the above cell if you mess up your dataframe.\n",
    "# print(df....)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Columns by name:\n",
    "We can select a single column by passing it's name in brackets, like: `df['column_name']`\n",
    "\n",
    "And we can select multiple columns by passing a list of column names in nested brackets: `df[['column1', 'column2', ...]]`\n",
    "\n",
    "This is a bit like string or list slicing, but using names or lists of names to take a selection of the available columns.\n",
    "\n",
    "We can use this to both get values from columns or to assign values directly into one or more columns, or to create new columns of some name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a single column is a series object, so sepal_lenghts is a series.\n",
    "sls = df['sepal_length']\n",
    "print('Some of the sepal lenghths are:\\n', sls)\n",
    "print('All the lenghts are:\\n', list(sls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Just like we did for the dataframe above, let's explore this \"sls\" series object.\n",
    "\n",
    "* Use the `.info(), .shape, .size` properties to learn about the object. \n",
    "* And Let's try some more interesting functions built into series objects: `.sum(), .value_counts(), .mean()`\n",
    "* Check if the series is greater than 3.  What is returned?  This list of True/False values is important for a future concept, \"masks\", for selecting rows.\n",
    "* Scroll through some of the methods listed in the series documentation here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and manipulating columns of data:\n",
    "We can perform mathematical operations on columns of data and put the result into a new or overwrite an existing column.  For example, if we want to add a column with units inches instead of cm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sepal_length_inches'] = df['sepal_length'] * 0.393701\n",
    "\n",
    "length_columns = sorted([c for c in df.columns if 'length' in c])\n",
    "print('length comparison:\\n', df[length_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you perform operations on a column, like multiplying the 'sepal_length' column by 0.393, that operation is broadcast across all rows in the column.  \n",
    "\n",
    "And when we perform operation aginst two columns, each row in the columns is matched with the same index row in the other column for the operation, as with the width_differenc calculation below.\n",
    "\n",
    "We can also select multiple columns py passing the columns in [], like: `df[['petal_length', 'petal_width']]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['width_difference'] = (df['sepal_width'] - df['petal_width']).abs()\n",
    "\n",
    "# Alternate ways of selecting and printing columns are commented out below:\n",
    "\n",
    "# width_columns = df.columns[df.columns.str.contains('width')]\n",
    "# width_columns = ['sepal_width', 'petal_width', 'width_difference']\n",
    "width_columns = sorted([c for c in df.columns if 'width' in c])\n",
    "\n",
    "print('Widths:')\n",
    "# print(df[['sepal_width', 'petal_width', 'width_difference']])\n",
    "print(df[width_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Rows with loc and iloc\n",
    "**.loc** vs **.iloc**\n",
    "* .loc selects rows with particular labels in the series or dataframe index\n",
    "  * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "* .iloc selects rows at integer locations within the series or dataframe.\n",
    "  * https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name  Age         City\n",
      "SSN                                   \n",
      "123-45-6789    Alice   25     New York\n",
      "234-56-7890      Bob   30  Los Angeles\n",
      "345-67-8901  Charlie   35      Chicago\n",
      "456-78-9012    David   40      Houston\n",
      "567-89-0123      Eve   45      Phoenix\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', \n",
    "             'Grace', 'Hannah', 'Isaac', 'Jack'],\n",
    "    'Age': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'SSN': ['123-45-6789', '234-56-7890', '345-67-8901', '456-78-9012', \n",
    "            '567-89-0123', '678-90-1234', '789-01-2345', '890-12-3456', \n",
    "            '901-23-4567', '123-45-5789'],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', \n",
    "             'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose'],\n",
    "})\n",
    "df = df.set_index('SSN')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set the index of our dataframe to the 'SSN' column, we can use loc to print rows with a specific SSN, or lists of SSNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A single row:\n",
      " Name      Charlie\n",
      "Age            35\n",
      "City    Saskatoon\n",
      "Name: 345-67-8901, dtype: object\n",
      "A list of rows by SSN:\n",
      "              Age       City\n",
      "SSN                        \n",
      "345-67-8901   35  Saskatoon\n",
      "456-78-9012   40    Houston\n",
      "A range of rows by SSN:\n",
      " SSN\n",
      "345-67-8901    Saskatoon\n",
      "456-78-9012      Houston\n",
      "567-89-0123      Phoenix\n",
      "Name: City, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print('A single row:\\n', \n",
    "      df.loc['345-67-8901'])\n",
    "print('A list of rows by SSN and a slice of columns from Age to City:\\n', \n",
    "      df.loc[['345-67-8901','456-78-9012'], 'Age':'City'])\n",
    "print('A range of rows by SSN:\\n',\n",
    "      df.loc['345-67-8901':'567-89-0123', 'City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can include a column name to print specific values or to set them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_ssn = '345-67-8901'\n",
    "print(f'{some_ssn} lives in:', df.loc[some_ssn, 'City'])\n",
    "df.loc[some_ssn, 'City'] = 'Saskatoon'\n",
    "print('Or was it:', df.loc[some_ssn, 'City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*:\n",
    "A few people have moved, please update their addresses:\n",
    "* People with SSNs '678-90-1234' and '789-01-2345'  didn't pay their taxes and are singing the blues in Folsom. \n",
    "* People with SSNs '890-12-3456', '901-23-4567', and '123-45-5789' are retiring and moved to Palm Beach.\n",
    "How would you do each of these one at a time with a loop, or all at once in a single operation?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loc selection of rows and columns\n",
    "Rather than selecting by index value with loc, we can use iloc to select by row address, like 0, 1 or 2, a list of addresses, [1, 2, 3], or a range of addresses, [2:6]. And same for the columns returned.  A few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 0:\n",
      " Name       Alice\n",
      "Age           25\n",
      "City    New York\n",
      "Name: 123-45-6789, dtype: object\n",
      "\n",
      "Rows 2 and 5 and Age column:\n",
      " SSN\n",
      "345-67-8901    35\n",
      "678-90-1234    50\n",
      "Name: Age, dtype: int64\n",
      "\n",
      "Rows 2:6 and columns 0 and 1 using slices:\n",
      "                 Name  Age\n",
      "SSN                      \n",
      "345-67-8901  Charlie   35\n",
      "456-78-9012    David   40\n",
      "567-89-0123      Eve   45\n",
      "678-90-1234    Frank   50\n",
      "789-01-2345    Grace   55\n"
     ]
    }
   ],
   "source": [
    "print('Row 0:\\n', \n",
    "      df.iloc[0])\n",
    "print('\\nRows 2 and 5 and Age column:\\n', \n",
    "      df.iloc[[2,5], 1])\n",
    "print('\\nRows 2:6 and columns 0 and 1 using slices:\\n', \n",
    "      df.iloc[2:7, :2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Just like with loc, we can assign values to rows and columns selected using .loc, and we can capture those selections in new dataframes as needed. \n",
    "\n",
    "Also notice that the SSN index is shown...   if you do a .reset_index, you'd instead see a new numerical index instead of the SSNs. \n",
    "We'll look more at the index below.\n",
    "\n",
    "#### *Exercise*\n",
    "Studies have shown that older people tend to be more fun than younger people. \n",
    "* Use iloc to creat two new dataframes called 'top_five' and 'bottom_five' from the top and bottom five rows from 'df'.  \n",
    "* Calculate the average age of each group and determine which group is likely to be the most fun!  You can compute the average of a column using .mean()... something like foo['col_name'].mean(). \n",
    "\n",
    "Do the cities that each group of people live in corroborate the results of the study, or is this silly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .iterrows() to iterate over rows\n",
    ".iterrows() returns an iterator that we can pair with a for loop to look at each row one at a time.  This isn't in the spirit of pandas, which would prefer that we do something to all of the rows at the same time, but it can be very useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row_index: 0\n",
      "Alice lives in New York and is 25 years old.\n",
      "We can use loc to get the name from the same row: Alice was here\n",
      "\n",
      "Row_index: 1\n",
      "Bob lives in Los Angeles and is 30 years old.\n",
      "We can use loc to get the name from the same row: Bob\n",
      "\n",
      "Row_index: 2\n",
      "Charlie lives in Saskatoon and is 35 years old.\n",
      "We can use loc to get the name from the same row: Charlie\n",
      "\n",
      "Row_index: 3\n",
      "David lives in Houston and is 40 years old.\n",
      "We can use loc to get the name from the same row: David\n",
      "\n",
      "Row_index: 4\n",
      "Eve lives in Phoenix and is 45 years old.\n",
      "We can use loc to get the name from the same row: Eve\n",
      "\n",
      "Row_index: 5\n",
      "Frank lives in Philadelphia and is 50 years old.\n",
      "We can use loc to get the name from the same row: Frank\n",
      "\n",
      "Row_index: 6\n",
      "Grace lives in San Antonio and is 55 years old.\n",
      "We can use loc to get the name from the same row: Grace\n",
      "\n",
      "Row_index: 7\n",
      "Hannah lives in San Diego and is 60 years old.\n",
      "We can use loc to get the name from the same row: Hannah\n",
      "\n",
      "Row_index: 8\n",
      "Isaac lives in Dallas and is 65 years old.\n",
      "We can use loc to get the name from the same row: Isaac\n",
      "\n",
      "Row_index: 9\n",
      "Jack lives in San Jose and is 70 years old.\n",
      "We can use loc to get the name from the same row: Jack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row_index, row_vals in df.iterrows():\n",
    "    # print out the name, city, and age of the person in this row:\n",
    "    # print(row[1]['Name'], 'lives in', row[1]['City'], 'and is', row[1]['Age'], 'years old.')\n",
    "    # the [1] is \n",
    "    print('Row_index:', row_index)\n",
    "    print(row_vals['Name'], 'lives in', row_vals['City'], 'and is', row_vals['Age'], 'years old.')\n",
    "    \n",
    "    if row_vals['Name'].startswith('A'):\n",
    "        df.loc[row_index, 'Name'] = df.loc[row_index, 'Name'] + ' was here'\n",
    "        \n",
    "    print('We can use loc to get the name from the same row:', df.loc[row_index, 'Name'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Use .reset_index() on the df and then iterrows again to see what is changed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting rows with a mask\n",
    "A mask is a way to say \"give me the rows where this condition is true.\"  In pandas, you create the mask by writing a conditional statement resulting in a list of true/false values.  Each true/false corresponds with a row in the dataframe. Applying the mask gives you only the rows with a corresponding true value.\n",
    "\n",
    "We'll look at conditional statements and then a mask example.\n",
    "\n",
    "### Conditional statements\n",
    "Here are a few examples of conditional statements:\n",
    "* Their age is greater than 30:\n",
    "  * `df['Age'] > 30`\n",
    "* Their name contains the letter 'a' and they are older than 40:\n",
    "  * `df['Name'].str.lower().str.contains('a') & (df['Age'] > 40)`\n",
    "* They are older than 50 or younger than 30:\n",
    "  * `(df['Age'] > 50) | (df['Age'] <= 30)`\n",
    "\n",
    "Note that rather than \"and\" and \"or\" in regular python code, we use \"&\" and \"|\" when comparing pandas series.  These are python bitwise operators. \n",
    "\n",
    "* Bitwise And: `a & b`\n",
    "* Bitwise Exclusive Or: `a ^ b`\n",
    "* Bitwise Inversion (not): `~ a`\n",
    "* Bitwise Or: `a | b`\n",
    "\n",
    "And when using & and |, we need to put parenthesees around the other expressions to make sure they are evaluated before the bitwise operators.  \n",
    "* This will error:\n",
    "  * `df['Age'] > 50 | df['Age'] <= 30`\n",
    "* This is correct:\n",
    "  * `(df['Age'] > 50) | (df['Age'] <= 30)`\n",
    "\n",
    "https://introcs.cs.princeton.edu/python/appendix_precedence/#:~:text=Order%20of%20Evaluation,the%20and%20or%20or%20operators.\n",
    "https://docs.python.org/3/library/operator.html#mapping-operators-to-functions\n",
    "\n",
    "### Example use of a mask to select some rows:\n",
    "Let's select all people/rows from our dataframe where their age is > 45:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_over_45 = df['Age'] > 45\n",
    "# mask_under_eq_45 = ~mask_over_45  # example of inverting/negating a mask\n",
    "# mask_under_eq_45 = df['Age'] <= 45  # this is equivelant to the line above\n",
    "df_over_45 = df[mask_over_45]\n",
    "# df_over_45 = df[df['Age'] > 45]  # this is equivelant to above.\n",
    "print(mask_over_45)\n",
    "print(df_over_45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Use conditional statements to make a mask and check .value_counts() on it to see how many people:\n",
    "* Are older than 60\n",
    "* Have social security numbers starting with '4'\n",
    "* Live in Philatelphia or are named Hannah\n",
    "* Do not live in Dallas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .query to select rows\n",
    ".query lets us use a sql like syntax to select rows.  This is nice becaues it can be more readable than a conditional statement for a mask, it might be better to use a mask for cases like:\n",
    "* Your column names have special characters\n",
    "* You are generating your query/condition programatically\n",
    "* You are using operations like .str.contains or other functions in your query.\n",
    "\n",
    "Documentation and a few good examples: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Name  Age     City\n",
      "SSN                               \n",
      "345-67-8901  Charlie   35  Chicago\n"
     ]
    }
   ],
   "source": [
    "filtered_df = df.query('Age > 30 and City == \"Chicago\"')\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dataframe Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/a8ksh4/python_workshop/main/SAMPLE_DATA/titaninc.csv\")\n",
    "# Note that by default, an arbitrary numerical index is assigned to the rows.\n",
    "# That default index would match exactly with the numeric address of each row, \n",
    "# so it is not useful for this example. \n",
    "# We instead set the passenger ID as the index - loc refers to this, and iloc \n",
    "# refers to the literal numerical address of each row. \n",
    "df = df.set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Exercise*\n",
    "Use iloc to show these views of the titanic passengers:\n",
    "* The 4th through 6th passengers\n",
    "* Even numbered passenger rows (not even PassengerId) and columns 1:4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .apply for arbitrary operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Note Regading inplace=True\n",
    "changed_dataframe = df.some_modification()\n",
    "\n",
    "Pandas is phasing out inplace modification.  It can still be done by passing the 'inplace=True'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Concatenation\n",
    "When we read in multiple files, we can concatenate them into a single dataframe.  \n",
    "Example should show adding an identifier row and pulling date from file name.\n",
    "\n",
    "## Join Operations\n",
    "\n",
    "## Stack and Unstack (sort of like a povit table)\n",
    "**Stack** - This function pivots the columns of a DataFrame into its index, effectively \"stacking\" the data vertically. It converts a DataFrame from a wide format to a long format.\n",
    "**Unstack** - This is the reverse of stack. It pivots the index of a DataFrame back into columns, converting it from a long format to a wide format.\n",
    "\n",
    "What does this mean and why!!!???\n",
    "\n",
    "## Plotting\n",
    "\n",
    "## Exporting files\n",
    "### Plain Excel\n",
    "### Multiple Sheets Excel\n",
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
